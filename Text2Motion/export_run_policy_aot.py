#!/usr/bin/env python3
"""
JITé¢„ç¼–è¯‘ç‰ˆæœ¬çš„run_policy pipeline

è¿™ä¸ªç‰ˆæœ¬é€šè¿‡ä»¥ä¸‹æ–¹å¼æ¶ˆé™¤JITå¼€é”€ï¼š
1. æ·±åº¦é¢„çƒ­æ‰€æœ‰JAXå‡½æ•°
2. ç¼“å­˜ç¼–è¯‘çŠ¶æ€
3. æ”¯æŒå¤šç§è¾“å…¥æ¨¡å¼çš„é¢„ç¼–è¯‘

è™½ç„¶ä¸æ˜¯çœŸæ­£çš„AOTç¼–è¯‘ï¼Œä½†å¯ä»¥å°†é¦–æ¬¡ä½¿ç”¨çš„JITå¼€é”€é™åˆ°æœ€ä½ã€‚

è¿è¡Œæ–¹æ³•:
    python export_run_policy_aot.py --model_path nn_ckpt/model-epoch=72-val_loss=0.003503.ckpt
"""

import argparse
import os
import pickle
import time
import tempfile
from typing import Tuple, Optional, Dict, Any

import numpy as np
import torch
import torch.nn as nn
import mujoco
import jax
import jax.numpy as jnp
from mujoco import mjx
import pytorch_lightning as pl

# å¯¼å…¥åŸå§‹çš„CEMæ§åˆ¶å™¨å’Œä»»åŠ¡
from hydrax.algs import CEM
from hydrax.tasks.humanoid_standonly import HumanoidStand


class MLPRegressor(pl.LightningModule):
    """ç¥ç»ç½‘ç»œæ¨¡å‹å®šä¹‰ï¼ˆä¸åŸå§‹ä¿æŒä¸€è‡´ï¼‰"""
    
    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim=1, learning_rate=1e-3):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, hidden_dim1),
            nn.BatchNorm1d(hidden_dim1),
            nn.ReLU(),
            
            nn.Linear(hidden_dim1, hidden_dim2),
            nn.BatchNorm1d(hidden_dim2),
            nn.ReLU(),
            
            nn.Linear(hidden_dim2, hidden_dim3),
            nn.BatchNorm1d(hidden_dim3),
            nn.ReLU(),
            
            nn.Linear(hidden_dim3, output_dim)
        )

    def forward(self, x):
        return self.model(x)


class PrecompiledRunPolicyPipeline:
    """JITé¢„ç¼–è¯‘ç‰ˆæœ¬çš„run_policy pipeline
    
    ç‰¹ç‚¹ï¼š
    1. æ·±åº¦é¢„çƒ­æ‰€æœ‰JAXå‡½æ•°è·¯å¾„
    2. æ¶ˆé™¤è¿è¡Œæ—¶JITç¼–è¯‘å¼€é”€
    3. æ¥è¿‘é™æ€çš„æ€§èƒ½è¡¨ç°
    4. ç®€å•å¯é çš„å®ç°
    """
    
    def __init__(
        self,
        pytorch_network: nn.Module,
        jax_task: Any,
        jax_controller: Any,
        device: str = 'cuda',
        # ä»¿çœŸå‚æ•°
        frequency: float = 50.0,
        plan_horizon: float = 0.5,
        sim_steps_per_replan: int = 2,
        step_dt: float = 0.02,
        # é¢„ç¼–è¯‘å‚æ•°
        precompile_depth: int = 3
    ):
        """åˆå§‹åŒ–é¢„ç¼–è¯‘pipeline
        
        Args:
            pytorch_network: è®­ç»ƒå¥½çš„PyTorchç½‘ç»œ
            jax_task: JAXä»»åŠ¡å¯¹è±¡
            jax_controller: JAX CEMæ§åˆ¶å™¨
            device: PyTorchè®¾å¤‡
            å…¶ä»–å‚æ•°: ä»¿çœŸå‚æ•°å’Œé¢„ç¼–è¯‘æ·±åº¦
        """
        self.device = torch.device(device)
        self.pytorch_network = pytorch_network.to(self.device).eval()
        self.jax_task = jax_task
        self.ctrl = jax_controller
        
        # ä»¿çœŸå‚æ•°
        self.frequency = frequency
        self.plan_horizon = plan_horizon
        self.sim_steps_per_replan = sim_steps_per_replan
        self.step_dt = step_dt
        
        print(f"é¢„ç¼–è¯‘Pipelineåˆå§‹åŒ–:")
        print(f"  - è§„åˆ’é¢‘ç‡: {frequency} Hz")
        print(f"  - è®¾å¤‡: {self.device}")
        print(f"  - é¢„ç¼–è¯‘æ·±åº¦: {precompile_depth}")
        
        # åˆå§‹åŒ–MuJoCoç¯å¢ƒ
        self._setup_mujoco_env()
        
        # æ·±åº¦é¢„ç¼–è¯‘æ‰€æœ‰JAXå‡½æ•°
        self._deep_precompile(precompile_depth)
        
        print("é¢„ç¼–è¯‘Pipelineåˆå§‹åŒ–å®Œæˆ!")
    
    def _setup_mujoco_env(self):
        """è®¾ç½®MuJoCoç¯å¢ƒ"""
        self.mj_model = self.jax_task.mj_model
        self.mj_data = mujoco.MjData(self.mj_model)
        
        # åˆå§‹åŒ–MJXæ•°æ®
        self.mjx_data_template = mjx.put_data(self.mj_model, self.mj_data)
        self.mjx_data_template = self.mjx_data_template.replace(
            mocap_pos=self.mj_data.mocap_pos, 
            mocap_quat=self.mj_data.mocap_quat
        )
        
        # åˆå§‹åŒ–ç­–ç•¥å‚æ•°
        self.policy_params_template = self.ctrl.init_params(initial_knots=None)
    
    def _deep_precompile(self, depth: int):
        """æ·±åº¦é¢„ç¼–è¯‘JAXå‡½æ•°"""
        print("å¼€å§‹æ·±åº¦é¢„ç¼–è¯‘JAXå‡½æ•°...")
        
        # 1. ç¼–è¯‘ä¼˜åŒ–å’Œæ’å€¼å‡½æ•°
        print("  ç¼–è¯‘æ ¸å¿ƒå‡½æ•°...")
        self.jit_optimize = jax.jit(self.ctrl.optimize)
        self.jit_interp_func = jax.jit(self.ctrl.interp_func)
        
        # 2. å¤šæ¨¡å¼é¢„çƒ­ç¼–è¯‘
        print(f"  è¿›è¡Œ{depth}è½®å¤šæ¨¡å¼é¢„çƒ­...")
        
        nq, nv = 48, 47  # G1æœºå™¨äººç»´åº¦
        
        for round_idx in range(depth):
            print(f"    é¢„çƒ­è½®æ¬¡ {round_idx + 1}/{depth}")
            
            # ç”Ÿæˆå¤šç§è¾“å…¥æ¨¡å¼
            variations = self._generate_input_variations(nq, nv, round_idx)
            
            for i, (qpos, qvel, time_val) in enumerate(variations):
                if i == 0:  # è¯¦ç»†è¾“å‡ºç¬¬ä¸€ä¸ª
                    start_time = time.time()
                
                # é¢„æµ‹knots
                predicted_knots = self.predict_knots_pytorch(qpos, qvel)
                
                # æ›´æ–°MJXæ•°æ®å’Œç­–ç•¥å‚æ•°
                mjx_data = self.mjx_data_template.replace(
                    qpos=jnp.array(qpos),
                    qvel=jnp.array(qvel),
                    time=time_val
                )
                policy_params = self.policy_params_template.replace(mean=predicted_knots)
                
                # CEMä¼˜åŒ–
                policy_params_out, rollouts = self.jit_optimize(mjx_data, policy_params)
                
                # æ’å€¼
                tq = jnp.arange(0, self.sim_steps_per_replan) * self.mj_model.opt.timestep + time_val
                tk = policy_params_out.tk
                knots = policy_params_out.mean[None, ...]
                controls = self.jit_interp_func(tq, tk, knots)[0]
                
                if i == 0:
                    elapsed = time.time() - start_time
                    print(f"      ç¬¬ä¸€æ¬¡æ‰§è¡Œè€—æ—¶: {elapsed:.4f}s")
        
        print("  æ·±åº¦é¢„ç¼–è¯‘å®Œæˆ!")
    
    def _generate_input_variations(self, nq: int, nv: int, round_idx: int):
        """ç”Ÿæˆå¤šç§è¾“å…¥å˜åŒ–ä»¥è§¦å‘æ‰€æœ‰ç¼–è¯‘è·¯å¾„"""
        variations = []
        
        # åŸºæœ¬ç§å­
        np.random.seed(42 + round_idx)
        
        # ä¸åŒå¹…åº¦çš„éšæœºçŠ¶æ€
        scales = [0.001, 0.01, 0.1, 0.5, 1.0]
        for scale in scales:
            qpos = np.random.randn(nq) * scale
            qvel = np.random.randn(nv) * scale
            time_val = round_idx * 0.1 + np.random.rand() * 0.1
            variations.append((qpos, qvel, time_val))
        
        # æå€¼æƒ…å†µ
        variations.append((np.zeros(nq), np.zeros(nv), 0.0))
        variations.append((np.ones(nq) * 0.1, np.ones(nv) * 0.1, 1.0))
        
        # æ··åˆæƒ…å†µ
        for _ in range(3):
            qpos = np.random.randn(nq) * 0.05
            qvel = np.random.randn(nv) * 0.05
            time_val = np.random.rand() * 2.0
            variations.append((qpos, qvel, time_val))
        
        return variations
    
    def predict_knots_pytorch(self, qpos: np.ndarray, qvel: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨PyTorchç½‘ç»œé¢„æµ‹knots"""
        with torch.no_grad():
            self.pytorch_network.eval()
            
            # çŠ¶æ€æ‹¼æ¥å’Œé¢„å¤„ç†
            state = np.concatenate([qpos, qvel], axis=0).astype(np.float32)
            state_tensor = torch.from_numpy(state).to(self.device).float().unsqueeze(0)
            
            # ç½‘ç»œæ¨ç†
            knots_flat = self.pytorch_network(state_tensor)
            knots = knots_flat.squeeze(0).cpu().numpy().reshape(4, 41)
            
            return knots
    
    def predict_controls(
        self,
        qpos: np.ndarray,
        qvel: np.ndarray,
        mocap_pos: Optional[np.ndarray] = None,
        mocap_quat: Optional[np.ndarray] = None,
        current_time: float = 0.0,
        return_timing: bool = False
    ) -> Tuple[np.ndarray, Optional[Dict[str, float]]]:
        """é¢„ç¼–è¯‘çš„æ§åˆ¶é¢„æµ‹ï¼ˆæœ€å°JITå¼€é”€ç‰ˆæœ¬ï¼‰"""
        total_start = time.time()
        timing_info = {} if return_timing else None
        
        # 1. PyTorchç¥ç»ç½‘ç»œé¢„æµ‹
        if return_timing:
            nn_start = time.time()
        
        predicted_knots = self.predict_knots_pytorch(qpos, qvel)
        
        if return_timing:
            timing_info['nn_time'] = time.time() - nn_start
        
        # 2. å‡†å¤‡JAXæ•°æ®
        if return_timing:
            prep_start = time.time()
        
        # æ›´æ–°MJXæ•°æ®
        mjx_data = self.mjx_data_template.replace(
            qpos=jnp.array(qpos),
            qvel=jnp.array(qvel),
            time=current_time
        )
        
        if mocap_pos is not None:
            mjx_data = mjx_data.replace(mocap_pos=jnp.array(mocap_pos))
        if mocap_quat is not None:
            mjx_data = mjx_data.replace(mocap_quat=jnp.array(mocap_quat))
        
        # æ›´æ–°ç­–ç•¥å‚æ•°
        policy_params = self.policy_params_template.replace(mean=predicted_knots)
        
        if return_timing:
            timing_info['prep_time'] = time.time() - prep_start
        
        # 3. é¢„ç¼–è¯‘çš„CEMä¼˜åŒ–ï¼ˆæœ€å°JITå¼€é”€ï¼‰
        if return_timing:
            cem_start = time.time()
        
        policy_params_out, rollouts = self.jit_optimize(mjx_data, policy_params)
        
        if return_timing:
            timing_info['cem_time'] = time.time() - cem_start
        
        # 4. é¢„ç¼–è¯‘çš„æ’å€¼ï¼ˆæœ€å°JITå¼€é”€ï¼‰
        if return_timing:
            interp_start = time.time()
        
        # æŸ¥è¯¢æ—¶é—´åºåˆ—
        tq = jnp.arange(0, self.sim_steps_per_replan) * self.mj_model.opt.timestep + current_time
        tk = policy_params_out.tk
        knots = policy_params_out.mean[None, ...]
        controls_jax = self.jit_interp_func(tq, tk, knots)[0]
        
        # è½¬æ¢ä¸ºnumpy
        controls = np.asarray(controls_jax)
        
        if return_timing:
            timing_info['interp_time'] = time.time() - interp_start
            timing_info['total_time'] = time.time() - total_start
        
        # è¿”å›ç»“æœ
        if return_timing:
            return controls, timing_info
        else:
            return controls, None
    
    def get_simulation_params(self) -> Dict[str, Any]:
        """è·å–ä»¿çœŸå‚æ•°ä¿¡æ¯"""
        return {
            'frequency': self.frequency,
            'sim_steps_per_replan': self.sim_steps_per_replan,
            'step_dt': self.step_dt,
            'plan_horizon': self.plan_horizon,
            'mujoco_timestep': self.mj_model.opt.timestep
        }


def create_and_precompile_pipeline(
    model_path: str,
    device: str = 'cuda',
    # CEMå‚æ•°
    num_samples: int = 500,
    num_elites: int = 20,
    sigma_start: float = 0.3,
    sigma_min: float = 0.05,
    plan_horizon: float = 0.5,
    num_knots: int = 4,
    iterations: int = 1,
    frequency: float = 50.0,
    # é¢„ç¼–è¯‘å‚æ•°
    precompile_depth: int = 3
):
    """åˆ›å»ºå¹¶é¢„ç¼–è¯‘pipeline"""
    print(f"å¼€å§‹åˆ›å»ºé¢„ç¼–è¯‘pipeline...")
    
    # 1. åŠ è½½PyTorchç½‘ç»œ
    print("åŠ è½½PyTorchç½‘ç»œ...")
    device_obj = torch.device(device)
    checkpoint = torch.load(model_path, map_location=device_obj)
    
    pl_net = MLPRegressor(95, 512, 512, 512, 164)
    pl_net.load_state_dict(checkpoint['state_dict'])
    net = pl_net.model
    net.to(device_obj).eval()
    
    # 2. è®¾ç½®MuJoCoä»»åŠ¡å’Œæ§åˆ¶å™¨
    print("è®¾ç½®ä»»åŠ¡å’Œæ§åˆ¶å™¨...")
    task = HumanoidStand()
    mj_model = task.mj_model
    
    # é…ç½®MuJoCoå‚æ•°
    mj_model.opt.timestep = 0.01
    mj_model.opt.iterations = 10
    mj_model.opt.ls_iterations = 50
    mj_model.opt.noslip_iterations = 2
    mj_model.opt.o_solimp = [0.0, 0.95, 0.01, 0.5, 2]
    mj_model.opt.enableflags = mujoco.mjtEnableBit.mjENBL_OVERRIDE
    
    ctrl = CEM(
        task,
        num_samples=num_samples, 
        num_elites=num_elites,
        sigma_start=sigma_start, 
        sigma_min=sigma_min,
        explore_fraction=0.3,
        plan_horizon=plan_horizon,
        spline_type="zero",
        num_knots=num_knots,
        iterations=iterations
    )
    
    # 3. è®¡ç®—ä»¿çœŸå‚æ•°
    sim_steps_per_replan = max(int((1.0 / frequency) / mj_model.opt.timestep), 1)
    step_dt = sim_steps_per_replan * mj_model.opt.timestep
    
    # 4. åˆ›å»ºé¢„ç¼–è¯‘pipeline
    print("åˆ›å»ºé¢„ç¼–è¯‘pipeline...")
    pipeline = PrecompiledRunPolicyPipeline(
        pytorch_network=net,
        jax_task=task,
        jax_controller=ctrl,
        device=device,
        frequency=frequency,
        plan_horizon=plan_horizon,
        sim_steps_per_replan=sim_steps_per_replan,
        step_dt=step_dt,
        precompile_depth=precompile_depth
    )
    
    return pipeline


def save_precompiled_pipeline(
    pipeline: PrecompiledRunPolicyPipeline,
    output_dir: str
):
    """ä¿å­˜é¢„ç¼–è¯‘pipelineé…ç½®"""
    print(f"ä¿å­˜é¢„ç¼–è¯‘pipelineé…ç½®åˆ°: {output_dir}")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜ç½‘ç»œå’Œé…ç½®
    config = {
        'pytorch_state_dict': pipeline.pytorch_network.state_dict(),
        'device': str(pipeline.device),
        'frequency': pipeline.frequency,
        'plan_horizon': pipeline.plan_horizon,
        'sim_steps_per_replan': pipeline.sim_steps_per_replan,
        'step_dt': pipeline.step_dt,
        # æ³¨æ„ï¼šMuJoCoæ¨¡å‹æ— æ³•ç›´æ¥åºåˆ—åŒ–XMLï¼Œæˆ‘ä»¬ä¿å­˜ä»»åŠ¡ç±»å‹
        'task_type': 'HumanoidStand',
        # CEMå‚æ•°
        'num_samples': pipeline.ctrl.num_samples,
        'num_elites': pipeline.ctrl.num_elites,
        'sigma_start': pipeline.ctrl.sigma_start,
        'sigma_min': pipeline.ctrl.sigma_min,
        'num_knots': pipeline.ctrl.num_knots,
        'iterations': pipeline.ctrl.iterations,
    }
    
    config_path = os.path.join(output_dir, "config.pkl")
    with open(config_path, 'wb') as f:
        pickle.dump(config, f)
    
    print(f"é…ç½®å·²ä¿å­˜!")


def load_precompiled_pipeline(compiled_dir: str, precompile_depth: int = 3) -> PrecompiledRunPolicyPipeline:
    """åŠ è½½é¢„ç¼–è¯‘pipeline"""
    print(f"åŠ è½½é¢„ç¼–è¯‘pipeline: {compiled_dir}")
    
    # åŠ è½½é…ç½®
    config_path = os.path.join(compiled_dir, "config.pkl")
    with open(config_path, 'rb') as f:
        config = pickle.load(f)
    
    # é‡å»ºPyTorchç½‘ç»œ
    device_obj = torch.device(config['device'])
    pl_net = MLPRegressor(95, 512, 512, 512, 164)
    net = pl_net.model
    net.load_state_dict(config['pytorch_state_dict'])
    net.to(device_obj).eval()
    
    # é‡å»ºJAXä»»åŠ¡ï¼ˆç›®å‰åªæ”¯æŒHumanoidStandï¼‰
    if config.get('task_type', 'HumanoidStand') == 'HumanoidStand':
        task = HumanoidStand()
    else:
        raise NotImplementedError(f"Task type {config['task_type']} not supported")
    
    mj_model = task.mj_model
    
    # é…ç½®MuJoCoå‚æ•°
    mj_model.opt.timestep = 0.01
    mj_model.opt.iterations = 10
    mj_model.opt.ls_iterations = 50
    mj_model.opt.noslip_iterations = 2
    mj_model.opt.o_solimp = [0.0, 0.95, 0.01, 0.5, 2]
    mj_model.opt.enableflags = mujoco.mjtEnableBit.mjENBL_OVERRIDE
    
    # é‡å»ºCEMæ§åˆ¶å™¨
    ctrl = CEM(
        task,
        num_samples=config['num_samples'], 
        num_elites=config['num_elites'],
        sigma_start=config['sigma_start'], 
        sigma_min=config['sigma_min'],
        explore_fraction=0.3,
        plan_horizon=config['plan_horizon'],
        spline_type="zero",
        num_knots=config['num_knots'],
        iterations=config['iterations']
    )
    
    # åˆ›å»ºé¢„ç¼–è¯‘pipeline
    pipeline = PrecompiledRunPolicyPipeline(
        pytorch_network=net,
        jax_task=task,
        jax_controller=ctrl,
        device=config['device'],
        frequency=config['frequency'],
        plan_horizon=config['plan_horizon'],
        sim_steps_per_replan=config['sim_steps_per_replan'],
        step_dt=config['step_dt'],
        precompile_depth=precompile_depth
    )
    
    return pipeline


def test_precompiled_pipeline(pipeline: PrecompiledRunPolicyPipeline, num_tests: int = 20):
    """æµ‹è¯•é¢„ç¼–è¯‘pipelineæ€§èƒ½"""
    print(f"\nğŸš€ æµ‹è¯•é¢„ç¼–è¯‘pipelineæ€§èƒ½ (è¿è¡Œ{num_tests}æ¬¡)...")
    
    # è·å–ä»¿çœŸå‚æ•°
    sim_params = pipeline.get_simulation_params()
    print("ä»¿çœŸå‚æ•°:")
    for key, value in sim_params.items():
        print(f"  {key}: {value}")
    
    nq, nv = 48, 47
    print(f"\næ¨¡å‹ç»´åº¦: nq={nq}, nv={nv}")
    
    # æ€§èƒ½æµ‹è¯•
    times = []
    
    print("\nè¯¦ç»†æµ‹è¯•:")
    for i in range(num_tests):
        # ç”ŸæˆéšæœºçŠ¶æ€
        qpos = np.random.randn(nq) * 0.1
        qvel = np.random.randn(nv) * 0.1
        
        # é¢„æµ‹æ§åˆ¶
        start_time = time.time()
        controls, timing_info = pipeline.predict_controls(
            qpos, qvel, 
            current_time=i * sim_params['step_dt'],
            return_timing=True
        )
        total_time = time.time() - start_time
        times.append(total_time)
        
        # æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼ˆå‰å‡ æ¬¡å’Œåå‡ æ¬¡ï¼‰
        if i < 3 or i >= num_tests - 3:
            print(f"\næµ‹è¯• #{i+1}:")
            print(f"  è¾“å…¥: qpos{qpos.shape}, qvel{qvel.shape}")
            print(f"  è¾“å‡º: controls{controls.shape}")
            print(f"  æ€»è€—æ—¶: {total_time:.4f}s")
            if timing_info:
                print(f"    - NNæ¨ç†: {timing_info['nn_time']:.4f}s")
                print(f"    - æ•°æ®å‡†å¤‡: {timing_info['prep_time']:.4f}s")
                print(f"    - CEMä¼˜åŒ–: {timing_info['cem_time']:.4f}s")
                print(f"    - æ’å€¼: {timing_info['interp_time']:.4f}s")
    
    # ç»Ÿè®¡ç»“æœ
    times = np.array(times)
    print(f"\nğŸ“Š é¢„ç¼–è¯‘æ€§èƒ½ç»Ÿè®¡ ({num_tests}æ¬¡æµ‹è¯•):")
    print(f"  å¹³å‡è€—æ—¶: {np.mean(times):.4f}s")
    print(f"  æœ€å°è€—æ—¶: {np.min(times):.4f}s")
    print(f"  æœ€å¤§è€—æ—¶: {np.max(times):.4f}s")
    print(f"  æ ‡å‡†å·®: {np.std(times):.4f}s")
    print(f"  ç†è®ºæœ€å¤§é¢‘ç‡: {1.0/np.mean(times):.2f} Hz")
    print(f"  ç›®æ ‡é¢‘ç‡: {sim_params['frequency']:.2f} Hz")
    print(f"  é¢‘ç‡è¾¾æˆç‡: {min(1.0, sim_params['frequency'] / (1.0/np.mean(times))) * 100:.1f}%")
    
    # æ€§èƒ½ä¸€è‡´æ€§æ£€æŸ¥
    if np.std(times) < 0.005:
        print("âœ… é¢„ç¼–è¯‘æˆåŠŸï¼šæ€§èƒ½éå¸¸ä¸€è‡´ï¼ŒJITå¼€é”€å·²æœ€å°åŒ–")
    elif np.std(times) < 0.01:
        print("âœ… é¢„ç¼–è¯‘åŸºæœ¬æˆåŠŸï¼šæ€§èƒ½è¾ƒä¸ºä¸€è‡´ï¼ŒJITå¼€é”€å·²å¤§å¹…å‡å°‘")
    else:
        print("âš ï¸ æ€§èƒ½æ³¢åŠ¨è¾ƒå¤§ï¼Œå¯èƒ½éœ€è¦æ›´æ·±åº¦çš„é¢„ç¼–è¯‘")


def main():
    parser = argparse.ArgumentParser(description="JITé¢„ç¼–è¯‘ç‰ˆæœ¬çš„run_policy pipeline")
    
    parser.add_argument(
        "--model_path", 
        type=str, 
        default="nn_ckpt/model-epoch=72-val_loss=0.003503.ckpt",
        help="PyTorchæ¨¡å‹checkpointè·¯å¾„"
    )
    
    parser.add_argument(
        "--output_dir",
        type=str,
        default="exported_models/precompiled",
        help="é¢„ç¼–è¯‘è¾“å‡ºç›®å½•"
    )
    
    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        help="PyTorchè®¡ç®—è®¾å¤‡"
    )
    
    # CEMå‚æ•°
    parser.add_argument("--num_samples", type=int, default=500, help="CEMæ ·æœ¬æ•°")
    parser.add_argument("--num_elites", type=int, default=20, help="CEMç²¾è‹±æ•°")
    parser.add_argument("--frequency", type=float, default=50.0, help="è§„åˆ’é¢‘ç‡")
    
    # é¢„ç¼–è¯‘å‚æ•°
    parser.add_argument("--precompile_depth", type=int, default=3, help="é¢„ç¼–è¯‘æ·±åº¦")
    
    parser.add_argument("--compile_only", action="store_true", help="ä»…é¢„ç¼–è¯‘ï¼Œä¸æµ‹è¯•")
    parser.add_argument("--test_only", action="store_true", help="ä»…æµ‹è¯•ç°æœ‰é¢„ç¼–è¯‘")
    
    args = parser.parse_args()
    
    if args.test_only:
        # ä»…æµ‹è¯•ç°æœ‰é¢„ç¼–è¯‘
        if os.path.exists(args.output_dir):
            pipeline = load_precompiled_pipeline(args.output_dir, args.precompile_depth)
            test_precompiled_pipeline(pipeline)
        else:
            print(f"é¢„ç¼–è¯‘ç›®å½•ä¸å­˜åœ¨: {args.output_dir}")
        return
    
    # åˆ›å»ºé¢„ç¼–è¯‘pipeline
    pipeline = create_and_precompile_pipeline(
        model_path=args.model_path,
        device=args.device,
        num_samples=args.num_samples,
        num_elites=args.num_elites,
        frequency=args.frequency,
        precompile_depth=args.precompile_depth
    )
    
    # ä¿å­˜é…ç½®
    save_precompiled_pipeline(pipeline, args.output_dir)
    
    if not args.compile_only:
        # æµ‹è¯•é¢„ç¼–è¯‘pipeline
        test_precompiled_pipeline(pipeline)
    
    print(f"\nğŸ‰ é¢„ç¼–è¯‘å®Œæˆ!")
    print(f"\nä½¿ç”¨æ–¹æ³•:")
    print(f"```python")
    print(f"from export_run_policy_aot import load_precompiled_pipeline")
    print(f"")
    print(f"# åŠ è½½é¢„ç¼–è¯‘pipelineï¼ˆæœ€å°JITå¼€é”€ï¼‰")
    print(f"planner = load_precompiled_pipeline('{args.output_dir}')")
    print(f"")
    print(f"# é¢„æµ‹æ§åˆ¶ï¼ˆæ¥è¿‘é™æ€æ€§èƒ½ï¼‰")
    print(f"controls, timing = planner.predict_controls(qpos, qvel, return_timing=True)")
    print(f"```")


if __name__ == "__main__":
    main() 