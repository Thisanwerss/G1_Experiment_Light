#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„run_policy pipelineï¼Œé€šè¿‡é¢„çƒ­å’Œç¼“å­˜æœ€å°åŒ–JITå¼€é”€

è¿™ä¸ªç‰ˆæœ¬é€šè¿‡ä»¥ä¸‹æ–¹å¼å‡å°‘JITå¼€é”€ï¼š
1. å……åˆ†çš„é¢„çƒ­ç¼–è¯‘ï¼ˆå¤šæ¬¡è°ƒç”¨ä¸åŒè¾“å…¥ï¼‰
2. ä½¿ç”¨JAXçš„ç¼–è¯‘ç¼“å­˜
3. ä¼˜åŒ–çš„æ•°æ®æµç®¡é“
4. æœ€å°åŒ–é‡æ–°ç¼–è¯‘çš„è§¦å‘

è¿è¡Œæ–¹æ³•:
    python export_run_policy_optimized.py --model_path nn_ckpt/model-epoch=72-val_loss=0.003503.ckpt
"""

import argparse
import os
import pickle
import time
from typing import Tuple, Optional, Dict, Any

import numpy as np
import torch
import torch.nn as nn
import mujoco
import jax
import jax.numpy as jnp
from mujoco import mjx
import pytorch_lightning as pl

# å¯¼å…¥åŸå§‹çš„CEMæ§åˆ¶å™¨å’Œä»»åŠ¡
from hydrax.algs import CEM
from hydrax.tasks.humanoid_standonly import HumanoidStand


class MLPRegressor(pl.LightningModule):
    """ç¥ç»ç½‘ç»œæ¨¡å‹å®šä¹‰ï¼ˆä¸åŸå§‹ä¿æŒä¸€è‡´ï¼‰"""
    
    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, output_dim=1, learning_rate=1e-3):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, hidden_dim1),
            nn.BatchNorm1d(hidden_dim1),
            nn.ReLU(),
            
            nn.Linear(hidden_dim1, hidden_dim2),
            nn.BatchNorm1d(hidden_dim2),
            nn.ReLU(),
            
            nn.Linear(hidden_dim2, hidden_dim3),
            nn.BatchNorm1d(hidden_dim3),
            nn.ReLU(),
            
            nn.Linear(hidden_dim3, output_dim)
        )

    def forward(self, x):
        return self.model(x)


class OptimizedRunPolicyPipeline:
    """ä¼˜åŒ–çš„run_policy pipeline
    
    é€šè¿‡å……åˆ†é¢„çƒ­ç¼–è¯‘æ¥æœ€å°åŒ–è¿è¡Œæ—¶JITå¼€é”€ï¼š
    1. æ·±åº¦é¢„çƒ­ï¼šä½¿ç”¨å¤šç§ä¸åŒè¾“å…¥æ¨¡å¼
    2. ç¼“å­˜å‹å¥½ï¼šé¿å…è§¦å‘é‡æ–°ç¼–è¯‘çš„æ“ä½œ
    3. æ•°æ®å¤ç”¨ï¼šé¢„åˆ†é…å’Œå¤ç”¨æ•°æ®ç»“æ„
    4. æ‰¹é‡ä¼˜åŒ–ï¼šå‡å°‘å‡½æ•°è°ƒç”¨å¼€é”€
    """
    
    def __init__(
        self,
        pytorch_network: nn.Module,
        jax_task: Any,
        jax_controller: Any,
        device: str = 'cuda',
        # CEMå‚æ•°
        num_samples: int = 500,
        num_elites: int = 20,
        sigma_start: float = 0.3,
        sigma_min: float = 0.05,
        plan_horizon: float = 0.5,
        num_knots: int = 4,
        iterations: int = 1,
        frequency: float = 50.0
    ):
        """åˆå§‹åŒ–ä¼˜åŒ–åçš„pipeline"""
        self.device = torch.device(device)
        self.pytorch_network = pytorch_network.to(self.device).eval()
        self.jax_task = jax_task
        self.jax_controller = jax_controller
        
        # è®¡ç®—å‚æ•°
        self.frequency = frequency
        self.replan_period = 1.0 / frequency
        self.plan_horizon = plan_horizon
        
        # é¢„è®¡ç®—ä»¿çœŸå‚æ•°
        mj_model = jax_task.mj_model
        self.sim_steps_per_replan = max(int(self.replan_period / mj_model.opt.timestep), 1)
        self.step_dt = self.sim_steps_per_replan * mj_model.opt.timestep
        
        print(f"ä¼˜åŒ–Pipelineåˆå§‹åŒ–:")
        print(f"  - è§„åˆ’é¢‘ç‡: {frequency} Hz")
        print(f"  - æ¯æ¬¡è§„åˆ’ä»¿çœŸæ­¥æ•°: {self.sim_steps_per_replan}")
        print(f"  - CEMæ ·æœ¬æ•°: {num_samples}")
        print(f"  - è®¾å¤‡: {self.device}")
        
        # æ·±åº¦é¢„çƒ­ç¼–è¯‘
        print("å¼€å§‹æ·±åº¦é¢„çƒ­ç¼–è¯‘...")
        self._deep_warmup_compilation()
        print("æ·±åº¦é¢„çƒ­ç¼–è¯‘å®Œæˆ!")
    
    def _deep_warmup_compilation(self):
        """æ·±åº¦é¢„çƒ­ç¼–è¯‘ï¼šä½¿ç”¨å¤šç§è¾“å…¥æ¨¡å¼å……åˆ†ç¼–è¯‘æ‰€æœ‰ä»£ç è·¯å¾„"""
        # åˆ›å»ºè™šæ‹Ÿçš„MuJoCoæ•°æ®ç”¨äºç¼–è¯‘
        mj_model = self.jax_task.mj_model
        mj_data = mujoco.MjData(mj_model)
        
        # è½¬æ¢ä¸ºJAXæ ¼å¼
        mjx_data = mjx.put_data(mj_model, mj_data)
        mjx_data = mjx_data.replace(
            mocap_pos=mj_data.mocap_pos, 
            mocap_quat=mj_data.mocap_quat
        )
        
        # åˆå§‹åŒ–æ§åˆ¶å™¨å‚æ•°
        dummy_knots = np.zeros((4, 41))
        policy_params = self.jax_controller.init_params(initial_knots=dummy_knots)
        
        # ç¼–è¯‘optimizeå‡½æ•°
        print("  æ·±åº¦ç¼–è¯‘CEMä¼˜åŒ–å‡½æ•°...")
        self.jit_optimize = jax.jit(self.jax_controller.optimize)
        
        # æ·±åº¦é¢„çƒ­ï¼šä½¿ç”¨å¤šç§ä¸åŒçš„çŠ¶æ€æ¨¡å¼
        compile_start = time.time()
        
        print("    é˜¶æ®µ1: åŸºç¡€ç¼–è¯‘...")
        for i in range(3):
            _, _ = self.jit_optimize(mjx_data, policy_params)
        
        print("    é˜¶æ®µ2: å¤šæ ·åŒ–çŠ¶æ€ç¼–è¯‘...")
        # ä½¿ç”¨ä¸åŒçš„çŠ¶æ€å’Œå‚æ•°æ¨¡å¼æ¥è§¦å‘æ‰€æœ‰ç¼–è¯‘è·¯å¾„
        for i in range(5):
            # éšæœºåŒ–çŠ¶æ€
            random_qpos = np.random.randn(mj_model.nq) * 0.1
            random_qvel = np.random.randn(mj_model.nv) * 0.1
            random_time = i * 0.1
            
            varied_mjx_data = mjx_data.replace(
                qpos=jnp.array(random_qpos),
                qvel=jnp.array(random_qvel),
                time=random_time
            )
            
            # éšæœºåŒ–knots
            random_knots = np.random.randn(4, 41) * 0.1
            varied_params = policy_params.replace(mean=random_knots)
            
            # æ‰§è¡Œç¼–è¯‘
            _, _ = self.jit_optimize(varied_mjx_data, varied_params)
        
        print("    é˜¶æ®µ3: æå€¼æ¡ˆä¾‹ç¼–è¯‘...")
        # æµ‹è¯•æå€¼æƒ…å†µ
        extreme_cases = [
            (np.zeros((mj_model.nq,)), np.zeros((mj_model.nv,))),  # å…¨é›¶çŠ¶æ€
            (np.ones((mj_model.nq,)), np.ones((mj_model.nv,))),   # å…¨ä¸€çŠ¶æ€
            (np.random.randn(mj_model.nq) * 5, np.random.randn(mj_model.nv) * 5),  # å¤§å¹…çŠ¶æ€
        ]
        
        for qpos, qvel in extreme_cases:
            extreme_mjx_data = mjx_data.replace(
                qpos=jnp.array(qpos),
                qvel=jnp.array(qvel)
            )
            _, _ = self.jit_optimize(extreme_mjx_data, policy_params)
        
        compile_time = time.time() - compile_start
        print(f"    CEMä¼˜åŒ–æ·±åº¦ç¼–è¯‘è€—æ—¶: {compile_time:.3f}s")
        
        # ç¼–è¯‘æ’å€¼å‡½æ•°
        print("  æ·±åº¦ç¼–è¯‘æ’å€¼å‡½æ•°...")
        self.jit_interp_func = jax.jit(self.jax_controller.interp_func)
        
        # æ·±åº¦é¢„çƒ­æ’å€¼å‡½æ•°
        tq_base = jnp.arange(0, self.sim_steps_per_replan) * mj_model.opt.timestep
        tk = policy_params.tk
        
        # ä½¿ç”¨ä¸åŒçš„æ—¶é—´åç§»å’Œknotsæ¨¡å¼
        for i in range(5):
            time_offset = i * 0.02
            tq = tq_base + time_offset
            
            # ä½¿ç”¨ä¸åŒçš„knots
            varied_knots = (policy_params.mean + np.random.randn(4, 41) * 0.1)[None, ...]
            _ = self.jit_interp_func(tq, tk, varied_knots)
        
        # ä¿å­˜ç¼–è¯‘åçš„å‚æ•°æ¨¡æ¿
        self.policy_params_template = policy_params
        self.mjx_data_template = mjx_data
        
        print("  æ‰€æœ‰JAXå‡½æ•°æ·±åº¦ç¼–è¯‘å®Œæˆ!")
    
    def predict_knots_pytorch(self, qpos: np.ndarray, qvel: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨PyTorchç½‘ç»œé¢„æµ‹knotsï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        with torch.no_grad():
            # çŠ¶æ€æ‹¼æ¥å’Œé¢„å¤„ç†ï¼ˆæ‰¹é‡åŒ–ï¼‰
            state = np.concatenate([qpos, qvel], axis=0).astype(np.float32)
            state_tensor = torch.from_numpy(state).to(self.device).float().unsqueeze(0)
            
            # ç½‘ç»œæ¨ç†
            knots_flat = self.pytorch_network(state_tensor)
            knots = knots_flat.squeeze(0).cpu().numpy().reshape(4, 41)
            
            return knots
    
    def predict_controls(
        self,
        qpos: np.ndarray,
        qvel: np.ndarray,
        mocap_pos: Optional[np.ndarray] = None,
        mocap_quat: Optional[np.ndarray] = None,
        current_time: float = 0.0,
        return_timing: bool = False
    ) -> Tuple[np.ndarray, Optional[Dict[str, float]]]:
        """ä¼˜åŒ–çš„æ§åˆ¶é¢„æµ‹ï¼ˆæœ€å°JITå¼€é”€ç‰ˆæœ¬ï¼‰"""
        total_start = time.time()
        timing_info = {} if return_timing else None
        
        # 1. PyTorchç¥ç»ç½‘ç»œé¢„æµ‹
        if return_timing:
            nn_start = time.time()
        
        predicted_knots = self.predict_knots_pytorch(qpos, qvel)
        
        if return_timing:
            timing_info['nn_time'] = time.time() - nn_start
        
        # 2. å‡†å¤‡JAXæ•°æ®ï¼ˆä¼˜åŒ–ï¼šå¤ç”¨æ¨¡æ¿ï¼Œåªæ›´æ–°å¿…è¦å­—æ®µï¼‰
        if return_timing:
            prep_start = time.time()
        
        # é«˜æ•ˆæ›´æ–°MJXæ•°æ®
        mjx_data = self.mjx_data_template.replace(
            qpos=jnp.array(qpos),
            qvel=jnp.array(qvel),
            time=current_time
        )
        
        if mocap_pos is not None:
            mjx_data = mjx_data.replace(mocap_pos=jnp.array(mocap_pos))
        if mocap_quat is not None:
            mjx_data = mjx_data.replace(mocap_quat=jnp.array(mocap_quat))
        
        # é«˜æ•ˆæ›´æ–°ç­–ç•¥å‚æ•°
        policy_params = self.policy_params_template.replace(mean=predicted_knots)
        
        if return_timing:
            timing_info['prep_time'] = time.time() - prep_start
        
        # 3. JAX CEMä¼˜åŒ–ï¼ˆå·²æ·±åº¦é¢„çƒ­ï¼Œåº”è¯¥æ— JITå¼€é”€ï¼‰
        if return_timing:
            cem_start = time.time()
        
        policy_params, rollouts = self.jit_optimize(mjx_data, policy_params)
        
        if return_timing:
            timing_info['cem_time'] = time.time() - cem_start
        
        # 4. JAXæ’å€¼ç”Ÿæˆæ§åˆ¶åºåˆ—ï¼ˆå·²æ·±åº¦é¢„çƒ­ï¼‰
        if return_timing:
            interp_start = time.time()
        
        # æŸ¥è¯¢æ—¶é—´åºåˆ—
        tq = jnp.arange(0, self.sim_steps_per_replan) * self.jax_task.mj_model.opt.timestep + current_time
        tk = policy_params.tk
        knots = policy_params.mean[None, ...]
        controls_jax = self.jit_interp_func(tq, tk, knots)[0]
        
        # è½¬æ¢ä¸ºnumpy
        controls = np.asarray(controls_jax)
        
        if return_timing:
            timing_info['interp_time'] = time.time() - interp_start
            timing_info['total_time'] = time.time() - total_start
        
        # è¿”å›ç»“æœ
        if return_timing:
            return controls, timing_info
        else:
            return controls, None
    
    def get_simulation_params(self) -> Dict[str, Any]:
        """è·å–ä»¿çœŸå‚æ•°ä¿¡æ¯"""
        return {
            'frequency': self.frequency,
            'replan_period': self.replan_period,
            'sim_steps_per_replan': self.sim_steps_per_replan,
            'step_dt': self.step_dt,
            'plan_horizon': self.plan_horizon,
            'mujoco_timestep': self.jax_task.mj_model.opt.timestep
        }


def create_optimized_pipeline(
    model_path: str,
    device: str = 'cuda',
    # CEMå‚æ•°
    num_samples: int = 500,
    num_elites: int = 20,
    sigma_start: float = 0.3,
    sigma_min: float = 0.05,
    plan_horizon: float = 0.5,
    num_knots: int = 4,
    iterations: int = 1,
    frequency: float = 50.0
) -> OptimizedRunPolicyPipeline:
    """åˆ›å»ºä¼˜åŒ–åçš„pipeline"""
    print(f"åˆ›å»ºä¼˜åŒ–çš„pipeline...")
    print(f"æ¨¡å‹è·¯å¾„: {model_path}")
    
    # 1. åŠ è½½PyTorchç½‘ç»œ
    print("åŠ è½½PyTorchç½‘ç»œ...")
    device_obj = torch.device(device)
    checkpoint = torch.load(model_path, map_location=device_obj)
    
    pl_net = MLPRegressor(95, 512, 512, 512, 164)
    pl_net.load_state_dict(checkpoint['state_dict'])
    net = pl_net.model
    net.to(device_obj).eval()
    print("PyTorchç½‘ç»œåŠ è½½å®Œæˆ")
    
    # 2. è®¾ç½®MuJoCoä»»åŠ¡å’Œæ¨¡å‹
    print("è®¾ç½®MuJoCoä»»åŠ¡...")
    task = HumanoidStand()
    mj_model = task.mj_model
    
    # é…ç½®MuJoCoå‚æ•°
    mj_model.opt.timestep = 0.01
    mj_model.opt.iterations = 10
    mj_model.opt.ls_iterations = 50
    mj_model.opt.noslip_iterations = 2
    mj_model.opt.o_solimp = [0.0, 0.95, 0.01, 0.5, 2]
    mj_model.opt.enableflags = mujoco.mjtEnableBit.mjENBL_OVERRIDE
    print("MuJoCoä»»åŠ¡è®¾ç½®å®Œæˆ")
    
    # 3. åˆ›å»ºJAX CEMæ§åˆ¶å™¨
    print("åˆ›å»ºJAX CEMæ§åˆ¶å™¨...")
    ctrl = CEM(
        task,
        num_samples=num_samples, 
        num_elites=num_elites,
        sigma_start=sigma_start, 
        sigma_min=sigma_min,
        explore_fraction=0.3,
        plan_horizon=plan_horizon,
        spline_type="zero",
        num_knots=num_knots,
        iterations=iterations
    )
    print("JAX CEMæ§åˆ¶å™¨åˆ›å»ºå®Œæˆ")
    
    # 4. åˆ›å»ºä¼˜åŒ–åçš„pipeline
    print("ç¼–è¯‘ä¼˜åŒ–pipeline...")
    pipeline = OptimizedRunPolicyPipeline(
        pytorch_network=net,
        jax_task=task,
        jax_controller=ctrl,
        device=device,
        num_samples=num_samples,
        num_elites=num_elites,
        sigma_start=sigma_start,
        sigma_min=sigma_min,
        plan_horizon=plan_horizon,
        num_knots=num_knots,
        iterations=iterations,
        frequency=frequency
    )
    
    print("ä¼˜åŒ–Pipelineåˆ›å»ºå®Œæˆ!")
    return pipeline


def save_optimized_pipeline(pipeline: OptimizedRunPolicyPipeline, output_path: str):
    """ä¿å­˜ä¼˜åŒ–åçš„pipelineé…ç½®"""
    print(f"ä¿å­˜ä¼˜åŒ–pipelineé…ç½®åˆ°: {output_path}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # ä¿å­˜é…ç½®ä¿¡æ¯
    config = {
        'pytorch_state_dict': pipeline.pytorch_network.state_dict(),
        'device': str(pipeline.device),
        'frequency': pipeline.frequency,
        'replan_period': pipeline.replan_period,
        'plan_horizon': pipeline.plan_horizon,
        'sim_steps_per_replan': pipeline.sim_steps_per_replan,
        'step_dt': pipeline.step_dt,
        'num_samples': pipeline.jax_controller.num_samples,
        'num_elites': pipeline.jax_controller.num_elites,
        'sigma_start': pipeline.jax_controller.sigma_start,
        'sigma_min': pipeline.jax_controller.sigma_min,
        'num_knots': pipeline.jax_controller.num_knots,
        'iterations': pipeline.jax_controller.iterations,
    }
    
    with open(output_path, 'wb') as f:
        pickle.dump(config, f)
    
    print(f"ä¼˜åŒ–Pipelineé…ç½®å·²ä¿å­˜: {output_path}")


def load_optimized_pipeline(pipeline_path: str) -> OptimizedRunPolicyPipeline:
    """åŠ è½½ä¼˜åŒ–åçš„pipelineï¼ˆåŒ…å«æ·±åº¦é¢„çƒ­ï¼‰"""
    print(f"åŠ è½½ä¼˜åŒ–pipeline: {pipeline_path}")
    
    with open(pipeline_path, 'rb') as f:
        config = pickle.load(f)
    
    print("é‡å»ºå¹¶ä¼˜åŒ–pipeline...")
    
    # 1. é¦–å…ˆé‡å»ºPyTorchç½‘ç»œ
    device_obj = torch.device(config['device'])
    pl_net = MLPRegressor(95, 512, 512, 512, 164)
    net = pl_net.model
    net.load_state_dict(config['pytorch_state_dict'])
    net.to(device_obj).eval()
    print("PyTorchç½‘ç»œé‡å»ºå®Œæˆ")
    
    # 2. è®¾ç½®MuJoCoä»»åŠ¡å’Œæ¨¡å‹
    print("è®¾ç½®MuJoCoä»»åŠ¡...")
    task = HumanoidStand()
    mj_model = task.mj_model
    
    # é…ç½®MuJoCoå‚æ•°
    mj_model.opt.timestep = 0.01
    mj_model.opt.iterations = 10
    mj_model.opt.ls_iterations = 50
    mj_model.opt.noslip_iterations = 2
    mj_model.opt.o_solimp = [0.0, 0.95, 0.01, 0.5, 2]
    mj_model.opt.enableflags = mujoco.mjtEnableBit.mjENBL_OVERRIDE
    print("MuJoCoä»»åŠ¡è®¾ç½®å®Œæˆ")
    
    # 3. åˆ›å»ºJAX CEMæ§åˆ¶å™¨
    print("åˆ›å»ºJAX CEMæ§åˆ¶å™¨...")
    ctrl = CEM(
        task,
        num_samples=config['num_samples'], 
        num_elites=config['num_elites'],
        sigma_start=config['sigma_start'], 
        sigma_min=config['sigma_min'],
        explore_fraction=0.3,
        plan_horizon=config['plan_horizon'],
        spline_type="zero",
        num_knots=config['num_knots'],
        iterations=config['iterations']
    )
    print("JAX CEMæ§åˆ¶å™¨åˆ›å»ºå®Œæˆ")
    
    # 4. åˆ›å»ºä¼˜åŒ–åçš„pipelineï¼ˆç›´æ¥æ„é€ ï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹ï¼‰
    print("ç¼–è¯‘ä¼˜åŒ–pipeline...")
    pipeline = OptimizedRunPolicyPipeline(
        pytorch_network=net,
        jax_task=task,
        jax_controller=ctrl,
        device=config['device'],
        num_samples=config['num_samples'],
        num_elites=config['num_elites'],
        sigma_start=config['sigma_start'],
        sigma_min=config['sigma_min'],
        plan_horizon=config['plan_horizon'],
        num_knots=config['num_knots'],
        iterations=config['iterations'],
        frequency=config['frequency']
    )
    
    print("ä¼˜åŒ–Pipelineé‡å»ºå®Œæˆ!")
    return pipeline


def test_optimized_pipeline(pipeline: OptimizedRunPolicyPipeline, num_tests: int = 10):
    """æµ‹è¯•ä¼˜åŒ–åçš„pipelineæ€§èƒ½"""
    print(f"\nğŸš€ æµ‹è¯•ä¼˜åŒ–pipelineæ€§èƒ½ (è¿è¡Œ{num_tests}æ¬¡)...")
    
    sim_params = pipeline.get_simulation_params()
    print("ä»¿çœŸå‚æ•°:")
    for key, value in sim_params.items():
        print(f"  {key}: {value}")
    
    nq, nv = 48, 47
    print(f"\næ¨¡å‹ç»´åº¦: nq={nq}, nv={nv}")
    
    # æ€§èƒ½æµ‹è¯•
    times = []
    consistency_check = []
    
    for i in range(num_tests):
        qpos = np.random.randn(nq) * 0.1
        qvel = np.random.randn(nv) * 0.1
        
        start_time = time.time()
        controls, timing_info = pipeline.predict_controls(
            qpos, qvel, 
            current_time=i * sim_params['step_dt'],
            return_timing=True
        )
        total_time = time.time() - start_time
        times.append(total_time)
        
        if timing_info:
            consistency_check.append(timing_info['cem_time'])
        
        # æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼ˆå‰å‡ æ¬¡ï¼‰
        if i < 3:
            print(f"\næµ‹è¯• #{i+1}:")
            print(f"  è¾“å…¥: qpos{qpos.shape}, qvel{qvel.shape}")
            print(f"  è¾“å‡º: controls{controls.shape}")
            print(f"  æ€»è€—æ—¶: {total_time:.4f}s")
            if timing_info:
                print(f"    - NNæ¨ç†: {timing_info['nn_time']:.4f}s")
                print(f"    - æ•°æ®å‡†å¤‡: {timing_info['prep_time']:.4f}s")
                print(f"    - CEMä¼˜åŒ–: {timing_info['cem_time']:.4f}s")
                print(f"    - æ’å€¼: {timing_info['interp_time']:.4f}s")
    
    # ç»Ÿè®¡ç»“æœ
    times = np.array(times)
    consistency_check = np.array(consistency_check)
    
    print(f"\nğŸ“Š ä¼˜åŒ–æ€§èƒ½ç»Ÿè®¡ ({num_tests}æ¬¡æµ‹è¯•):")
    print(f"  å¹³å‡è€—æ—¶: {np.mean(times):.4f}s")
    print(f"  æœ€å°è€—æ—¶: {np.min(times):.4f}s")
    print(f"  æœ€å¤§è€—æ—¶: {np.max(times):.4f}s")
    print(f"  æ ‡å‡†å·®: {np.std(times):.4f}s")
    print(f"  ç†è®ºæœ€å¤§é¢‘ç‡: {1.0/np.mean(times):.2f} Hz")
    print(f"  ç›®æ ‡é¢‘ç‡: {sim_params['frequency']:.2f} Hz")
    
    # ä¸€è‡´æ€§æ£€æŸ¥
    cem_std = np.std(consistency_check)
    print(f"\nğŸ“ˆ ä¼˜åŒ–æ•ˆæœè¯„ä¼°:")
    print(f"  CEMæ—¶é—´æ ‡å‡†å·®: {cem_std:.4f}s")
    if cem_std < 0.005:
        print("  âœ… ä¼˜åŒ–æˆåŠŸï¼šCEMæ€§èƒ½éå¸¸ä¸€è‡´")
    elif cem_std < 0.02:
        print("  âš¡ ä¼˜åŒ–è‰¯å¥½ï¼šCEMæ€§èƒ½åŸºæœ¬ä¸€è‡´")
    else:
        print("  âš ï¸ ä»æœ‰ä¼˜åŒ–ç©ºé—´ï¼šCEMæ€§èƒ½å­˜åœ¨æ³¢åŠ¨")
    
    # é¦–æ¬¡è°ƒç”¨æ£€æŸ¥
    if len(times) > 1:
        first_vs_rest = times[0] / np.mean(times[1:])
        print(f"  é¦–æ¬¡è°ƒç”¨å€æ•°: {first_vs_rest:.2f}x")
        if first_vs_rest < 2:
            print("  âœ… æ·±åº¦é¢„çƒ­æˆåŠŸï¼šé¦–æ¬¡è°ƒç”¨æ— æ˜æ˜¾å¼€é”€")
        else:
            print("  âš ï¸ ä»å­˜åœ¨é¦–æ¬¡è°ƒç”¨å¼€é”€")


def main():
    parser = argparse.ArgumentParser(description="ä¼˜åŒ–çš„run_policy pipeline")
    
    parser.add_argument(
        "--model_path", 
        type=str, 
        default="nn_ckpt/model-epoch=72-val_loss=0.003503.ckpt",
        help="PyTorchæ¨¡å‹checkpointè·¯å¾„"
    )
    
    parser.add_argument(
        "--output_dir",
        type=str,
        default="exported_models",
        help="è¾“å‡ºç›®å½•"
    )
    
    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        help="PyTorchè®¡ç®—è®¾å¤‡"
    )
    
    # CEMå‚æ•°
    parser.add_argument("--num_samples", type=int, default=500, help="CEMæ ·æœ¬æ•°")
    parser.add_argument("--num_elites", type=int, default=20, help="CEMç²¾è‹±æ•°")
    parser.add_argument("--frequency", type=float, default=50.0, help="è§„åˆ’é¢‘ç‡")
    
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•ä¼˜åŒ–åçš„pipeline")
    parser.add_argument("--test_only", action="store_true", help="ä»…æµ‹è¯•ç°æœ‰pipeline")
    
    args = parser.parse_args()
    
    output_path = os.path.join(args.output_dir, "run_policy_optimized.pkl")
    
    if args.test_only:
        if os.path.exists(output_path):
            pipeline = load_optimized_pipeline(output_path)
            test_optimized_pipeline(pipeline)
        else:
            print(f"ä¼˜åŒ–Pipelineæ–‡ä»¶ä¸å­˜åœ¨: {output_path}")
        return
    
    # åˆ›å»ºå¹¶ä¿å­˜ä¼˜åŒ–pipeline
    pipeline = create_optimized_pipeline(
        model_path=args.model_path,
        device=args.device,
        num_samples=args.num_samples,
        num_elites=args.num_elites,
        frequency=args.frequency
    )
    
    save_optimized_pipeline(pipeline, output_path)
    
    # æµ‹è¯•pipeline
    if args.test:
        test_optimized_pipeline(pipeline)
    
    print(f"\nğŸ‰ ä¼˜åŒ–Pipelineåˆ›å»ºå®Œæˆ!")
    print(f"\nå…³é”®ä¼˜åŒ–:")
    print(f"  âœ… æ·±åº¦é¢„çƒ­ç¼–è¯‘ï¼šä½¿ç”¨å¤šç§è¾“å…¥æ¨¡å¼")
    print(f"  âœ… æ•°æ®ç»“æ„å¤ç”¨ï¼šå‡å°‘å†…å­˜åˆ†é…")
    print(f"  âœ… æ‰¹é‡æ“ä½œä¼˜åŒ–ï¼šå‡å°‘å‡½æ•°è°ƒç”¨å¼€é”€")
    print(f"  âœ… ç¼“å­˜å‹å¥½è®¾è®¡ï¼šé¿å…é‡æ–°ç¼–è¯‘è§¦å‘")
    print(f"\nä½¿ç”¨æ–¹æ³•:")
    print(f"```python")
    print(f"from export_run_policy_optimized import load_optimized_pipeline")
    print(f"planner = load_optimized_pipeline('{output_path}')")
    print(f"controls, timing = planner.predict_controls(qpos, qvel, return_timing=True)")
    print(f"```")


if __name__ == "__main__":
    main() 